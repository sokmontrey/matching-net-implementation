{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9243,"sourceType":"datasetVersion","datasetId":2243}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\nfrom torchvision import datasets\nfrom torchvision.transforms import ToTensor\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport pandas as pd\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np","metadata":{"_uuid":"016e871d-ee9f-4725-9cc1-ed7c9f10dceb","_cell_guid":"ff21f8de-0df8-471d-9a86-863c9d20f640","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-09T15:38:29.954044Z","iopub.execute_input":"2025-02-09T15:38:29.954418Z","iopub.status.idle":"2025-02-09T15:38:38.513338Z","shell.execute_reply.started":"2025-02-09T15:38:29.954380Z","shell.execute_reply":"2025-02-09T15:38:38.512304Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"N_SAMPLES_PER_CLASS = 7000\nN_CLASSES_TOTAL = 10\nTRAIN_SIZE = 0.5 # / NUM_CLASS\nN_TRAIN_CLASSES = int(TRAIN_SIZE * N_CLASSES_TOTAL)\nN_TEST_CLASSES = int((1 - TRAIN_SIZE) * N_CLASSES_TOTAL)\nBATCH_SIZE = 32\n\nN_SUPPORTS = 3\nN_QUERIES = 5\n\nEMBEDDING_DIM = 32\n# N_K = 1\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T15:38:38.514604Z","iopub.execute_input":"2025-02-09T15:38:38.515198Z","iopub.status.idle":"2025-02-09T15:38:38.525257Z","shell.execute_reply.started":"2025-02-09T15:38:38.515156Z","shell.execute_reply":"2025-02-09T15:38:38.524023Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Load CSV files\n_train_df = pd.read_csv(\"/kaggle/input/fashionmnist/fashion-mnist_train.csv\")\n_test_df = pd.read_csv(\"/kaggle/input/fashionmnist/fashion-mnist_test.csv\")\ndf = pd.concat([_train_df, _test_df])\ndf.sort_values('label', inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T15:38:38.526729Z","iopub.execute_input":"2025-02-09T15:38:38.527204Z","iopub.status.idle":"2025-02-09T15:38:45.701662Z","shell.execute_reply.started":"2025-02-09T15:38:38.527159Z","shell.execute_reply":"2025-02-09T15:38:45.700322Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"train_df = df[:N_TRAIN_CLASSES * N_SAMPLES_PER_CLASS]\ntest_df = df[N_TRAIN_CLASSES * N_SAMPLES_PER_CLASS:]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T15:38:45.704354Z","iopub.execute_input":"2025-02-09T15:38:45.704752Z","iopub.status.idle":"2025-02-09T15:38:45.709735Z","shell.execute_reply.started":"2025-02-09T15:38:45.704721Z","shell.execute_reply":"2025-02-09T15:38:45.708529Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"class FashionMnistEpisodicDataset(Dataset):\n    def __init__(self, dataframe, n_supports=3, n_queries=5, n_episodes=1000,\n                 n_total_classes=5, n_samples_per_class=7000, is_train=False):\n        \n        self.labels = torch.tensor(dataframe.iloc[:, 0].values, dtype=torch.long)  \n        self.images = torch.tensor(dataframe.iloc[:, 1:].values, dtype=torch.float32).view(-1, 1, 28, 28) / 255.0\n\n        self.n_supports = n_supports\n        self.n_queries = n_queries\n        self.n_episodes = n_episodes\n        self.n_total_classes = n_total_classes\n        self.n_samples_per_class = n_samples_per_class\n        self.is_train = is_train\n\n        # Precompute indices for classes\n        self.class_indices = {c: torch.where(self.labels == c)[0] for c in range(n_total_classes)}\n\n    def __len__(self):\n        return self.n_episodes \n\n    def __getitem__(self, _):\n        # Sample unique classes for support\n        support_classes = np.random.choice(self.n_total_classes, self.n_supports, replace=False)\n        query_classes = np.random.choice(support_classes, self.n_queries, replace=True)\n\n        # Efficiently sample indices from each class\n        support_indices = torch.cat([self.class_indices[c][torch.randint(0, len(self.class_indices[c]), (1,))] for c in support_classes])\n        query_indices = torch.cat([self.class_indices[c][torch.randint(0, len(self.class_indices[c]), (1,))] for c in query_classes])\n\n        # Vectorized indexing\n        support_images, support_labels = self.images[support_indices], self.labels[support_indices]\n        query_images, query_labels = self.images[query_indices], self.labels[query_indices]\n\n        return support_images, support_labels, query_images, query_labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T15:38:45.711672Z","iopub.execute_input":"2025-02-09T15:38:45.712047Z","iopub.status.idle":"2025-02-09T15:38:45.730033Z","shell.execute_reply.started":"2025-02-09T15:38:45.712021Z","shell.execute_reply":"2025-02-09T15:38:45.729041Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"train_dataset = FashionMnistEpisodicDataset(\n    train_df,\n    n_supports=N_SUPPORTS,\n    n_queries=N_QUERIES,\n    n_total_classes=N_TRAIN_CLASSES,\n    n_samples_per_class=N_SAMPLES_PER_CLASS,\n)\n\ntrain_dataloader = DataLoader(\n        train_dataset,\n        batch_size=BATCH_SIZE,\n        shuffle=False,\n        num_workers=4,\n        pin_memory=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T15:38:45.731162Z","iopub.execute_input":"2025-02-09T15:38:45.731525Z","iopub.status.idle":"2025-02-09T15:38:46.276453Z","shell.execute_reply.started":"2025-02-09T15:38:45.731492Z","shell.execute_reply":"2025-02-09T15:38:46.275086Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Expect x of shape Batch N, Eps N, C, W, H\nclass ConvEmbedding(nn.Module):\n    def __init__(self, embedding_dim=32):\n        super().__init__()\n        self.conv1 = nn.Sequential(\n            nn.Conv2d(1,16,kernel_size=3, bias=False),\n            nn.BatchNorm2d(16),\n            nn.MaxPool2d((2,2)),\n            nn.ReLU(),\n        )\n        self.conv2 = nn.Sequential(\n            nn.Conv2d(16,32,kernel_size=3, bias=False),\n            nn.BatchNorm2d(32),\n            nn.MaxPool2d((2,2)),\n            nn.ReLU(),\n        )\n        self.adaptive_avg_pool = nn.AdaptiveAvgPool2d((1,1))\n        self.fully_connected = nn.Linear(32,embedding_dim)\n\n    def forward(self, x):\n        N_B, Eps_Size, C, W, H = x.shape\n        x = x.view(N_B * Eps_Size, C, W, H)\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.adaptive_avg_pool(x)\n        x = torch.flatten(x, start_dim=1)\n        x = self.fully_connected(x)\n        x = x.view(N_B, Eps_Size, -1)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T15:38:46.287659Z","iopub.execute_input":"2025-02-09T15:38:46.287996Z","iopub.status.idle":"2025-02-09T15:38:46.301419Z","shell.execute_reply.started":"2025-02-09T15:38:46.287965Z","shell.execute_reply":"2025-02-09T15:38:46.300265Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Appendix: A.2\n# _g: embedded supports: N, S, E\n# N:  Batch size\n# S:  Support size\n# E:  Embedding dim\nclass SupportFullyConditionalEmbedding(nn.Module):\n    def __init__(self, embedding_dim=32):\n        super().__init__()\n        self.embedding_dim = embedding_dim\n        self.bi_lstm = nn.LSTM(input_size=embedding_dim,\n                               hidden_size=embedding_dim,\n                               bidirectional=True, \n                               batch_first=True)\n\n    def forward(self, _g):\n        output, _ = self.bi_lstm(_g)                                     # N, S, 2E\n        # Using lstm output because it contains hidden state for every timestep. \n        # TODO: verify this later\n        h_fwd, h_bwd = torch.split(output, self.embedding_dim, dim = 2)  # N, S, E\n        g = h_fwd + h_bwd + _g                                           # N, S, E\n        return g","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T19:42:13.430671Z","iopub.execute_input":"2025-02-09T19:42:13.431168Z","iopub.status.idle":"2025-02-09T19:42:13.437152Z","shell.execute_reply.started":"2025-02-09T19:42:13.431135Z","shell.execute_reply":"2025-02-09T19:42:13.436265Z"}},"outputs":[],"execution_count":235},{"cell_type":"code","source":"# Appendix: A.1\n# g:  conditionally embedded supports: N, S, E\n# _f: embedded queries: N, Q, E\n# N:  Batch size\n# S:  Support size\n# Q:  Query size\n# E:  Embedding dim\nclass QueryFullyConditionalEmbedding(nn.Module):\n    def __init__(self, embedding_dim=32, K=3):\n        super().__init__()\n        self.K = K\n        self.embedding_dim=embedding_dim\n        self.lstm = nn.LSTMCell(input_size=embedding_dim,\n                                hidden_size=embedding_dim * 2)\n        self.projection = nn.Linear(embedding_dim*2, embedding_dim)\n\n    def forward(self, g, _f):\n        N, S, E = g.shape                                      # N, S, E\n        _, Q, _ = _f.shape                                     # N, Q, E\n        \n        h0 = torch.zeros(N, Q, E)                              # N, Q, E\n        c0 = torch.zeros(N, Q, 2*E)                            # N, Q, 2E\n\n        hk, ck = h0, c0\n        hk_list = []\n        \n        for k in range(self.K):\n            att = F.softmax(torch.bmm(\n                hk,                                            # N, Q, E\n                g.transpose(1,2)                               # N, E, S\n            ), dim=1)                                          # N, Q, S\n            #                             (N,Q,S,E) * (N,Q,S,1) = N, Q, S, E\n            attw = g.unsqueeze(1).expand(-1, Q, -1, -1) * att.unsqueeze(-1)\n            \n            rk = torch.sum(attw, dim=2)                        # N, Q, E\n            hk_rk = torch.concat([hk, rk], dim=2)              # N, Q, 2E\n            \n            _h, _c = self.lstm(_f.view(N*Q, E), (              # N*Q,  E\n                            hk_rk.view(N*Q, 2*E),              # N*Q,  2E\n                               ck.view(N*Q, 2*E)))             # N*Q,  2E\n\n            ck = _c.view(N, Q, 2*E)                            # N, Q, 2E\n            hk = projection(_h).view(N, Q, E) + _f             # N, Q, E\n            hk_list.append(hk.unsqueeze(0))                    # 1, N, Q, E\n\n        hk_list = torch.concat(hk_list, dim=0)                 # K, N, Q, E\n        return hk_list[-1]                                     # N, Q, E\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T19:44:21.532052Z","iopub.execute_input":"2025-02-09T19:44:21.532462Z","iopub.status.idle":"2025-02-09T19:44:21.540559Z","shell.execute_reply.started":"2025-02-09T19:44:21.532435Z","shell.execute_reply":"2025-02-09T19:44:21.539559Z"}},"outputs":[],"execution_count":241},{"cell_type":"code","source":"support_images, support_labels, query_images, query_labels = next(iter(train_dataloader))\nsupport_images.shape, support_labels.shape, query_images.shape, query_labels.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T19:44:21.701282Z","iopub.execute_input":"2025-02-09T19:44:21.701655Z","iopub.status.idle":"2025-02-09T19:44:21.888166Z","shell.execute_reply.started":"2025-02-09T19:44:21.701625Z","shell.execute_reply":"2025-02-09T19:44:21.887183Z"}},"outputs":[{"execution_count":242,"output_type":"execute_result","data":{"text/plain":"(torch.Size([32, 3, 1, 28, 28]),\n torch.Size([32, 3]),\n torch.Size([32, 5, 1, 28, 28]),\n torch.Size([32, 5]))"},"metadata":{}}],"execution_count":242},{"cell_type":"code","source":"embedded_supports = ConvEmbedding()(support_images)\nembedded_queries = ConvEmbedding()(query_images)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T19:44:21.889594Z","iopub.execute_input":"2025-02-09T19:44:21.889932Z","iopub.status.idle":"2025-02-09T19:44:21.969484Z","shell.execute_reply.started":"2025-02-09T19:44:21.889897Z","shell.execute_reply":"2025-02-09T19:44:21.968708Z"}},"outputs":[],"execution_count":243},{"cell_type":"code","source":"embedded_supports.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T19:44:21.970695Z","iopub.execute_input":"2025-02-09T19:44:21.970949Z","iopub.status.idle":"2025-02-09T19:44:21.977136Z","shell.execute_reply.started":"2025-02-09T19:44:21.970927Z","shell.execute_reply":"2025-02-09T19:44:21.975986Z"}},"outputs":[{"execution_count":244,"output_type":"execute_result","data":{"text/plain":"torch.Size([32, 3, 32])"},"metadata":{}}],"execution_count":244},{"cell_type":"code","source":"conditioned_embedded_supports = SupportFullyConditionalEmbedding()(embedded_supports)\nconditioned_embedded_supports.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T19:44:23.989709Z","iopub.execute_input":"2025-02-09T19:44:23.989992Z","iopub.status.idle":"2025-02-09T19:44:24.000543Z","shell.execute_reply.started":"2025-02-09T19:44:23.989970Z","shell.execute_reply":"2025-02-09T19:44:23.999749Z"}},"outputs":[{"name":"stdout","text":"OUTPUT:  torch.Size([32, 3, 64])\n","output_type":"stream"},{"execution_count":245,"output_type":"execute_result","data":{"text/plain":"torch.Size([32, 3, 32])"},"metadata":{}}],"execution_count":245},{"cell_type":"code","source":"conditioned_embedded_queries = QueryFullyConditionalEmbedding()(conditioned_embedded_supports, embedded_queries)\nconditioned_embedded_queries.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T19:44:24.596677Z","iopub.execute_input":"2025-02-09T19:44:24.596961Z","iopub.status.idle":"2025-02-09T19:44:24.609299Z","shell.execute_reply.started":"2025-02-09T19:44:24.596939Z","shell.execute_reply":"2025-02-09T19:44:24.608166Z"}},"outputs":[{"execution_count":246,"output_type":"execute_result","data":{"text/plain":"torch.Size([32, 5, 32])"},"metadata":{}}],"execution_count":246},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}