{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9243,"sourceType":"datasetVersion","datasetId":2243}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\nfrom torchvision import datasets\nfrom torchvision.transforms import ToTensor\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport pandas as pd\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np","metadata":{"_uuid":"016e871d-ee9f-4725-9cc1-ed7c9f10dceb","_cell_guid":"ff21f8de-0df8-471d-9a86-863c9d20f640","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-09T15:38:29.954044Z","iopub.execute_input":"2025-02-09T15:38:29.954418Z","iopub.status.idle":"2025-02-09T15:38:38.513338Z","shell.execute_reply.started":"2025-02-09T15:38:29.954380Z","shell.execute_reply":"2025-02-09T15:38:38.512304Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"N_SAMPLES_PER_CLASS = 7000\nN_CLASSES_TOTAL = 10\nTRAIN_SIZE = 0.5 # / NUM_CLASS\nN_TRAIN_CLASSES = int(TRAIN_SIZE * N_CLASSES_TOTAL)\nN_TEST_CLASSES = int((1 - TRAIN_SIZE) * N_CLASSES_TOTAL)\nBATCH_SIZE = 32\n\nN_SUPPORTS = 3\nN_QUERIES = 5\n\nEMBEDDING_DIM = 32\n# N_K = 1\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T15:38:38.514604Z","iopub.execute_input":"2025-02-09T15:38:38.515198Z","iopub.status.idle":"2025-02-09T15:38:38.525257Z","shell.execute_reply.started":"2025-02-09T15:38:38.515156Z","shell.execute_reply":"2025-02-09T15:38:38.524023Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Load CSV files\n_train_df = pd.read_csv(\"/kaggle/input/fashionmnist/fashion-mnist_train.csv\")\n_test_df = pd.read_csv(\"/kaggle/input/fashionmnist/fashion-mnist_test.csv\")\ndf = pd.concat([_train_df, _test_df])\ndf.sort_values('label', inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T15:38:38.526729Z","iopub.execute_input":"2025-02-09T15:38:38.527204Z","iopub.status.idle":"2025-02-09T15:38:45.701662Z","shell.execute_reply.started":"2025-02-09T15:38:38.527159Z","shell.execute_reply":"2025-02-09T15:38:45.700322Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"train_df = df[:N_TRAIN_CLASSES * N_SAMPLES_PER_CLASS]\ntest_df = df[N_TRAIN_CLASSES * N_SAMPLES_PER_CLASS:]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T15:38:45.704354Z","iopub.execute_input":"2025-02-09T15:38:45.704752Z","iopub.status.idle":"2025-02-09T15:38:45.709735Z","shell.execute_reply.started":"2025-02-09T15:38:45.704721Z","shell.execute_reply":"2025-02-09T15:38:45.708529Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"class FashionMnistEpisodicDataset(Dataset):\n    def __init__(self, dataframe, n_supports=3, n_queries=5, n_episodes=1000,\n                 n_total_classes=5, n_samples_per_class=7000, is_train=False):\n        \n        self.labels = torch.tensor(dataframe.iloc[:, 0].values, dtype=torch.long)  \n        self.images = torch.tensor(dataframe.iloc[:, 1:].values, dtype=torch.float32).view(-1, 1, 28, 28) / 255.0\n\n        self.n_supports = n_supports\n        self.n_queries = n_queries\n        self.n_episodes = n_episodes\n        self.n_total_classes = n_total_classes\n        self.n_samples_per_class = n_samples_per_class\n        self.is_train = is_train\n\n        # Precompute indices for classes\n        self.class_indices = {c: torch.where(self.labels == c)[0] for c in range(n_total_classes)}\n\n    def __len__(self):\n        return self.n_episodes \n\n    def __getitem__(self, _):\n        # Sample unique classes for support\n        support_classes = np.random.choice(self.n_total_classes, self.n_supports, replace=False)\n        query_classes = np.random.choice(support_classes, self.n_queries, replace=True)\n\n        # Efficiently sample indices from each class\n        support_indices = torch.cat([self.class_indices[c][torch.randint(0, len(self.class_indices[c]), (1,))] for c in support_classes])\n        query_indices = torch.cat([self.class_indices[c][torch.randint(0, len(self.class_indices[c]), (1,))] for c in query_classes])\n\n        # Vectorized indexing\n        support_images, support_labels = self.images[support_indices], self.labels[support_indices]\n        query_images, query_labels = self.images[query_indices], self.labels[query_indices]\n\n        return support_images, support_labels, query_images, query_labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T15:38:45.711672Z","iopub.execute_input":"2025-02-09T15:38:45.712047Z","iopub.status.idle":"2025-02-09T15:38:45.730033Z","shell.execute_reply.started":"2025-02-09T15:38:45.712021Z","shell.execute_reply":"2025-02-09T15:38:45.729041Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"train_dataset = FashionMnistEpisodicDataset(\n    train_df,\n    n_supports=N_SUPPORTS,\n    n_queries=N_QUERIES,\n    n_total_classes=N_TRAIN_CLASSES,\n    n_samples_per_class=N_SAMPLES_PER_CLASS,\n)\n\ntrain_dataloader = DataLoader(\n        train_dataset,\n        batch_size=BATCH_SIZE,\n        shuffle=False,\n        num_workers=4,\n        pin_memory=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T15:38:45.731162Z","iopub.execute_input":"2025-02-09T15:38:45.731525Z","iopub.status.idle":"2025-02-09T15:38:46.276453Z","shell.execute_reply.started":"2025-02-09T15:38:45.731492Z","shell.execute_reply":"2025-02-09T15:38:46.275086Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Expect x of shape Batch N, Eps N, C, W, H\nclass ConvEmbedding(nn.Module):\n    def __init__(self, embedding_dim=32):\n        super().__init__()\n        self.conv1 = nn.Sequential(\n            nn.Conv2d(1,16,kernel_size=3, bias=False),\n            nn.BatchNorm2d(16),\n            nn.MaxPool2d((2,2)),\n            nn.ReLU(),\n        )\n        self.conv2 = nn.Sequential(\n            nn.Conv2d(16,32,kernel_size=3, bias=False),\n            nn.BatchNorm2d(32),\n            nn.MaxPool2d((2,2)),\n            nn.ReLU(),\n        )\n        self.adaptive_avg_pool = nn.AdaptiveAvgPool2d((1,1))\n        self.fully_connected = nn.Linear(32,embedding_dim)\n\n    def forward(self, x):\n        N_B, Eps_Size, C, W, H = x.shape\n        x = x.view(N_B * Eps_Size, C, W, H)\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.adaptive_avg_pool(x)\n        x = torch.flatten(x, start_dim=1)\n        x = self.fully_connected(x)\n        x = x.view(N_B, Eps_Size, -1)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T15:38:46.287659Z","iopub.execute_input":"2025-02-09T15:38:46.287996Z","iopub.status.idle":"2025-02-09T15:38:46.301419Z","shell.execute_reply.started":"2025-02-09T15:38:46.287965Z","shell.execute_reply":"2025-02-09T15:38:46.300265Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Appendix: A.2\nclass SupportFullyConditionalEmbedding(nn.Module):\n    def __init__(self, embedding_dim=32):\n        super().__init__()\n        self.embedding_dim = embedding_dim\n        self.bi_lstm = nn.LSTM(input_size=embedding_dim,\n                               hidden_size=embedding_dim,\n                               bidirectional=True, \n                               batch_first=True)\n\n    # embedded_supports: NxSxE (N: batch, S: support size, E: embedding dim)\n    def forward(self, embedded_supports):\n        output, _ = self.bi_lstm(embedded_supports)\n        # Using output because it contains hidden state for every timestep. TODO: have to verify this later\n        h_fwd, h_bwd = torch.split(output, self.embedding_dim, dim = 2)\n        conditioned_embedded_supports = h_fwd + h_bwd + embedded_supports\n        return conditioned_embedded_supports","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T15:39:46.890815Z","iopub.execute_input":"2025-02-09T15:39:46.891196Z","iopub.status.idle":"2025-02-09T15:39:46.896889Z","shell.execute_reply.started":"2025-02-09T15:39:46.891164Z","shell.execute_reply":"2025-02-09T15:39:46.895907Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}